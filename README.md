# Decoding-methods-for-language-generation

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1BSF3jR4fZH6K6FaGzDp9iJuZ0dEL-XJ_?usp=sharing)

- Validated claims made in the paper  [The Curious case of neural degeneration](https://arxiv.org/pdf/1904.09751.pdf).
- Explored text generation coherence and diversity for top-p (nucleus sampling), beam search and pure sampling. 
- Applied aforementioned decoding strategies on a pretrained transformer-based GPT2 model to depict superior performance of nucleus sampling.
